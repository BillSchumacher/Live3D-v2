# Live3D v2 (AttNR ) 

Neural Rendering with Attention: An Incremental Improvement for Anime Character Animation

[Draft] | 
[Code](https://github.com/transpchan/Live3D-v2/) |
[Email](mailto:transpchan@gmail.com) |
[Discord](https://discord.gg/Md3cykbn36) |
[Twitter](https://twitter.com/transpchan) |
[Bilibili](https://space.bilibili.com/6418569) |
[Zhihu](https://zhuanlan.zhihu.com/p/565391665)

### Project history


<i>2022/08</i> @transpchan was kicked out from the authors of  [Live3Dv1](https://github.com/transpchan/Live3D) as I refused to continue submittion after seeing the [heart-breaking reviews](https://github.com/transpchan/Live3D) from ECCV22. 

**Call for Authors/Contributors: Please contact me if you are willing to be the author of the paper of v2 and future versions, if you are familiar with academic journals or conferences.  Pull requests are also welcome!!**

<i>2022/10</i> Live3Dv2 is released. Changes are (1) dropping the ResNet50 encoder. (2) adding self-attention to the U-Net (3) tuning the hyper-parms of the networks

<i>2022/11</i> Weight file for Live3Dv2 is released. 

<i>2022/11</i> Stay tuned for [Live3D v3](https://github.com/transpchan/Live3D-v3)
### Try it yourself!


**[Demo1] [Generate videos](https://transpchan.github.io/live3d/#demo1)**

**[Demo2] [Colorize your own model](https://transpchan.github.io/live3d/#demo2)**

**[Demo3] [Generate 3D point cloud from drawings](https://transpchan.github.io/live3d/#demo3)**


![visitor](https://count.getloli.com/get/@live3d?theme=gelbooru)
