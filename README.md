# Live3D v2 (CoNR with Attention) 

CoNR with Attention: An Incremental Improvement for Anime Character Animation

[Draft] | 
[Code](https://github.com/transpchan/Live3D-v2/) |
[Email](mailto:transpchan@gmail.com) |
[Discord](https://discord.gg/Md3cykbn36) |
[Twitter](https://twitter.com/transpchan) |
[Bilibili](https://space.bilibili.com/6418569)

### Project history


<i>2022/08</i> @transpchan was kicked out from the authors of  [Live3Dv1](https://github.com/transpchan/Live3D) as I refused to continue submittion after seeing the heart-breaking reviews from ECCV22. Futher submittion of Live3Dv1 might still be done by other coauthors, but they refuse to help me writing the paper of Live3Dv2 or future versions. **Author position are open again. Please contact me if you are willing to help me cover future progress.**

<i>2022/10</i> Live3Dv2 is released. Changes are (1) dropping the ResNet50 encoder and replace it with tuned encoder. (2) adding self-attention to the U-Net (3) tuning the hyper-parms of the networks


### Try it yourself!


**[Demo1] [Generate videos](https://transpchan.github.io/live3d/#demo1)**

**[Demo2] [Colorize your own model](https://transpchan.github.io/live3d/#demo2)**

**[Demo3] [Generate 3D point cloud from drawings](https://transpchan.github.io/live3d/#demo3)**


![visitor](https://count.getloli.com/get/@live3d?theme=gelbooru)
